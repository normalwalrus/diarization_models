{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyannote.metrics\n",
    "%pip install pyannote.core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "from pyannote.core import Annotation, Timeline, Segment\n",
    "\n",
    "def read_rttm_file_into_annotation(rttm_path):\n",
    "\n",
    "    speaker_segments = Annotation()\n",
    "    \n",
    "    with open(rttm_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if parts[0] == \"SPEAKER\": \n",
    "                speaker = parts[7]\n",
    "                start_time = float(parts[3])\n",
    "                duration = float(parts[4])\n",
    "                end_time = start_time + duration\n",
    "\n",
    "                speaker_segments[Segment(round(start_time, 2), round(end_time,2))] = speaker\n",
    "\n",
    "    return speaker_segments\n",
    "\n",
    "def compute_der(hyp_rttm_path, ref_rttm_path):\n",
    "    \"\"\"\n",
    "    Compute Diarization Error Rate (DER) allowing overlap.\n",
    "    \n",
    "    :param reference: Ground truth diarization (pyannote Annotation)\n",
    "    :param hypothesis: Predicted diarization (pyannote Annotation)\n",
    "    :return: DER score\n",
    "    \"\"\"\n",
    "    metric = DiarizationErrorRate()\n",
    "    hypothesis = read_rttm_file_into_annotation(hyp_rttm_path)\n",
    "    reference = read_rttm_file_into_annotation(ref_rttm_path)\n",
    "\n",
    "    der_score = metric(reference, hypothesis)\n",
    "    return der_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyannote\\metrics\\utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nemo's DER: 0.2010746232204104\n",
      "Pyannote's DER: 0.12757080199863757\n",
      "Reverb's DER: 0.30597759166352895\n"
     ]
    }
   ],
   "source": [
    "import simpleder\n",
    "\n",
    "nemo_rttm_path = 'outputs/nemo_test.rttm'\n",
    "pyannote_rttm_path = 'outputs/pyannote_test.rttm'\n",
    "reverb_rttm_path = 'outputs/reverb_test.rttm'\n",
    "\n",
    "reference_rttm_path = 'ami_dataset/IS1002c.Mix-Headset.rttm'\n",
    "\n",
    "nemo_error = compute_der(nemo_rttm_path, reference_rttm_path)\n",
    "pyannote_error = compute_der(pyannote_rttm_path, reference_rttm_path)\n",
    "reverb_error = compute_der(reverb_rttm_path, reference_rttm_path)\n",
    "\n",
    "print(f\"Nemo's DER: {nemo_error}\")\n",
    "print(f\"Pyannote's DER: {pyannote_error}\")\n",
    "print(f\"Reverb's DER: {reverb_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 10!\n",
      "We are at 20!\n",
      "We are at 30!\n",
      "We are at 40!\n",
      "We are at 50!\n",
      "We are at 60!\n",
      "Average Nemo DER score : 0.29836731683560935\n",
      "Average Pyannote DER score : 0.17433728142179777\n",
      "Average Reverb DER score : 0.4054601903876826\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "rttm_files_done = [f for f in os.listdir('outputs/reverb') if f.endswith(\".rttm\")]\n",
    "\n",
    "PATH_TO_NEMO = 'outputs/nemo/'\n",
    "PATH_TO_PYANNOTE = 'outputs/pyannote/'\n",
    "PATH_TO_REVERB = 'outputs/reverb/'\n",
    "\n",
    "PATH_TO_REFERENCE = 'ami_dataset/rttm/'\n",
    "\n",
    "nemo_scores = []\n",
    "pyannote_scores = []\n",
    "reverb_scores = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for rttm_file in rttm_files_done:\n",
    "\n",
    "    nemo_rttm_path = PATH_TO_NEMO + rttm_file\n",
    "    pyannote_rttm_path = PATH_TO_PYANNOTE + rttm_file\n",
    "    reverb_rttm_path = PATH_TO_REVERB + rttm_file\n",
    "\n",
    "    reference_rttm_path = PATH_TO_REFERENCE + rttm_file\n",
    "    \n",
    "    nemo_error = compute_der(nemo_rttm_path, reference_rttm_path)\n",
    "    pyannote_error = compute_der(pyannote_rttm_path, reference_rttm_path)\n",
    "    reverb_error = compute_der(reverb_rttm_path, reference_rttm_path)\n",
    "\n",
    "    nemo_scores.append(nemo_error)\n",
    "    pyannote_scores.append(pyannote_error)\n",
    "    reverb_scores.append(reverb_error)\n",
    "\n",
    "    count+=1\n",
    "    if count % 10 == 0:\n",
    "        print(f\"We are at {count}!\")\n",
    "\n",
    "print(f\"Average Nemo DER score : {sum(nemo_scores)/len(nemo_scores)}\")\n",
    "print(f\"Average Pyannote DER score : {sum(pyannote_scores)/len(pyannote_scores)}\")\n",
    "print(f\"Average Reverb DER score : {sum(reverb_scores)/len(reverb_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
